{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Skenario 8 - CNN DenseNet121 - SVM**\n",
    "\n",
    "Skenario 8 menggunakan model Convolutional Neural Network (CNN) dengan arsitektur DenseNet121 sebagai ekstraksi fitur dan SVM sebagai algoritma untuk melakukan klasifikasi pada data citra otak.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages\n",
    "\n",
    "Impor semua pustaka dan modul yang dibutuhkan untuk pemrosesan data, visualisasi, pembuatan model, dan pelatihan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Input, Dense,GlobalAveragePooling2D,Flatten,MaxPool2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load dan Eksplorasi Data\n",
    "Load dan proses data `image_selected.npz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    base_dir = r\"D:\\Users\\RESA\\Coding\\Alzheimer-Classification-with-CNN-SVM\\Notebook\\Preprocessing\\image_selected.npz\"\n",
    "    \n",
    "    # Load data from npz file\n",
    "    loaded_data = np.load(base_dir, allow_pickle=True)\n",
    "    loaded_combined_slices = loaded_data[list(loaded_data.keys())[0]]\n",
    "\n",
    "    # Prepare X dan Y lists\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    # Buat label mapping untuk tiap kelas \n",
    "    label_mapping = {'AD': 0, 'CN': 1, 'EMCI': 2, 'LMCI': 3}\n",
    "\n",
    "    # Iterate through loaded data\n",
    "    for label, plane_slices in loaded_combined_slices.item().items():\n",
    "        for plane, slices in plane_slices.items():\n",
    "            for selected_slice in slices:\n",
    "                position, resized_slice = selected_slice\n",
    "\n",
    "                # Pastikan resized_slice memiliki tiga saluran warna\n",
    "                resized_slice_rgb = cv2.cvtColor(resized_slice, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "                # Append data to X and Y\n",
    "                X.append(resized_slice_rgb)\n",
    "                Y.append(label_mapping[label])\n",
    "\n",
    "    # Convert lists ke numpy arrays\n",
    "    X = np.array(X) / 255.0  # Normalisasi\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    # Convert labels to categorical format\n",
    "    Y = to_categorical(Y, num_classes=len(set(Y)))\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panggil fungsi dan simpan ke X, Y\n",
    "X, Y = load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (7200, 224, 224, 3)\n",
      "Y shape: (7200, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi Kelas setelah One-Hot Encoding:\n",
      "{0: 1800, 1: 1800, 2: 1800, 3: 1800}\n"
     ]
    }
   ],
   "source": [
    "unique_labels, counts = np.unique(np.argmax(Y, axis=1), return_counts=True)\n",
    "class_distribution = dict(zip(tuple(unique_labels), counts))\n",
    "\n",
    "print(\"Distribusi Kelas setelah One-Hot Encoding:\")\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pembagian Data\n",
    "Data dibagi dengan rasio 80:20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cek shape dan jumlah data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi X_train: (5760, 224, 224, 3)\n",
      "Dimensi Y_train: (5760, 4)\n",
      "Dimensi X_test: (1440, 224, 224, 3)\n",
      "Dimensi Y_test: (1440, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensi X_train:\", X_train.shape)\n",
    "print(\"Dimensi Y_train:\", Y_train.shape)\n",
    "print(\"Dimensi X_test:\", X_test.shape)\n",
    "print(\"Dimensi Y_test:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah sampel dalam X_train: 5760\n",
      "Jumlah sampel dalam Y_train: 5760\n",
      "Jumlah sampel dalam X_test: 1440\n",
      "Jumlah sampel dalam Y_test: 1440\n"
     ]
    }
   ],
   "source": [
    "print(\"Jumlah sampel dalam X_train:\", len(X_train))\n",
    "print(\"Jumlah sampel dalam Y_train:\", len(Y_train))\n",
    "print(\"Jumlah sampel dalam X_test:\", len(X_test))\n",
    "print(\"Jumlah sampel dalam Y_test:\", len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Buat dan Konfigurasi Model Ekstraksi Fitur\n",
    "Arsitektur yang digunakan sebagai ekstraksi fitur adalah DenseNet121 yang merupakan dari transfer learning yaitu arsitektur yang sudah dilatih dengan data ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model yang udah dilatih sebelumnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_path = r\"D:\\Users\\RESA\\Coding\\Evaluasi\\h_DenseNet121.h5\"\n",
    "loaded_model = load_model(model_path, custom_objects={'specificity': specificity, 'sensitivity': sensitivity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train features: (5760, 224, 224, 3)\n",
      "Shape of test features: (1440, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "extractCNN = Model(loaded_model.inputs, loaded_model.layers[-4].output)\n",
    "feat_trainCNN = extractCNN.predict(X_train)\n",
    "feat_testCNN = extractCNN.predict(X_test)\n",
    "print(\"Shape of train features:\", feat_trainCNN.shape)\n",
    "print(\"Shape of test features:\", feat_testCNN.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_feat_trainCNN = feat_trainCNN.reshape((feat_trainCNN.shape[0], -1))\n",
    "flat_feat_testCNN = feat_testCNN.reshape((feat_testCNN.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi train sebelum reshaping: (5760, 224, 224, 3)\n",
      "Dimensi train setelah reshaping: (5760, 150528)\n",
      "Dimensi test sebelum reshaping: (1440, 224, 224, 3)\n",
      "Dimensi test setelah reshaping: (1440, 150528)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensi train sebelum reshaping:\", feat_trainCNN.shape)\n",
    "print(\"Dimensi train setelah reshaping:\", flat_feat_trainCNN.shape)\n",
    "print(\"Dimensi test sebelum reshaping:\", feat_testCNN.shape)\n",
    "print(\"Dimensi test setelah reshaping:\", flat_feat_testCNN.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Model - Cross Validation\n",
    "Latih model dengan data `X_train dan Y_train` dan menguji kinerja model pada data validasi `X_test dan Y_test`, setelah pelatihan nanti model akan menyimpan riwayatnya ke dalam `h_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Kernel RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf = SVC(kernel='rbf', probability=True, decision_function_shape='ovr')\n",
    "scores_rbf = cross_val_score(svm_rbf, flat_feat_trainCNN, np.argmax(Y_train, axis=1), cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Skor Akurasi untuk Setiap Fold:\")\n",
    "print(scores_rbf)\n",
    "print(\"\\nRata-rata Skor Akurasi:\")\n",
    "print(scores_rbf.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_predictions_rbf = cross_val_predict(svm_rbf, flat_feat_trainCNN, np.argmax(Y_train, axis=1), cv=5, method='predict_proba')\n",
    "\n",
    "best_rbf_fold_index = np.argmax(scores_rbf)\n",
    "best_rbf_fold_y_test = np.argmax(Y_train, axis=1)\n",
    "best_rbf_fold_y_pred = fold_predictions_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simpan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm_rbf = r\"D:/Users/RESA/Coding/Evaluasi/densenet121_svm_model_rbf.pkl\"\n",
    "with open(model_svm_rbf, 'wb') as model_file:\n",
    "    pickle.dump(svm_rbf, model_file)\n",
    "print(\"Model SVM RBF telah disimpan di:\", model_svm_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf.fit(flat_feat_trainCNN, np.argmax(Y_train, axis=1))\n",
    "predictions_test = svm_rbf.predict(flat_feat_testCNN)\n",
    "print(\"Label Sebenarnya:\")\n",
    "print(np.argmax(Y_test, axis=1))\n",
    "print(\"\\nLabel Prediksi:\")\n",
    "print(predictions_test)\n",
    "accuracy_test = np.mean(predictions_test == np.argmax(Y_test, axis=1))\n",
    "print(\"\\nAkurasi pada Data Uji:\", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(best_rbf_fold_y_pred, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report for the Fold with the Highest Accuracy:\")\n",
    "print(classification_report(best_rbf_fold_y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, 6), scores_rbf, marker='o', linestyle='-', color='blue')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Cross-Validation Scores')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_rbf = confusion_matrix(best_rbf_fold_y_test, predicted_labels)\n",
    "\n",
    "# Visualisasi confusion matrix menggunakan heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_rbf, annot=True, fmt='g', cmap='viridis', xticklabels=True, yticklabels=True)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = conf_matrix_rbf[1, 1] / (conf_matrix_rbf[1, 0] + conf_matrix_rbf[1, 1])\n",
    "specificity = conf_matrix_rbf[0, 0] / (conf_matrix_rbf[0, 0] + conf_matrix_rbf[0, 1])\n",
    "\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Kernel Polinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly = SVC(kernel='poly', probability=True, decision_function_shape='ovr')\n",
    "scores_poly = cross_val_score(svm_poly, flat_feat_trainCNN, np.argmax(Y_train, axis=1), cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Skor Akurasi untuk Setiap Fold:\")\n",
    "print(scores_poly)\n",
    "print(\"\\nRata-rata Skor Akurasi:\")\n",
    "print(scores_poly.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_predictions = cross_val_predict(svm_poly, flat_feat_trainCNN, np.argmax(Y_train, axis=1), cv=5, method='predict_proba')\n",
    "\n",
    "best_poly_fold_index = np.argmax(scores_poly)\n",
    "best_poly_fold_y_test = np.argmax(Y_train, axis=1)\n",
    "best_poly_fold_y_pred = fold_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simpan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm_poly = r\"D:/Users/RESA/Coding/Evaluasi/densenet121_svm_model_poly.pkl\"\n",
    "with open(model_svm_poly, 'wb') as model_file:\n",
    "    pickle.dump(svm_poly, model_file)\n",
    "print(\"Model SVM poly telah disimpan di:\", model_svm_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly.fit(flat_feat_trainCNN, np.argmax(Y_train, axis=1))\n",
    "predictions_test = svm_poly.predict(flat_feat_testCNN)\n",
    "print(\"Label Sebenarnya:\")\n",
    "print(np.argmax(Y_test, axis=1))\n",
    "print(\"\\nLabel Prediksi:\")\n",
    "print(predictions_test)\n",
    "accuracy_test = np.mean(predictions_test == np.argmax(Y_test, axis=1))\n",
    "print(\"\\nAkurasi pada Data Uji:\", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(best_poly_fold_y_pred, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report for the Fold with the Highest Accuracy:\")\n",
    "print(classification_report(best_poly_fold_y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, 6), scores_poly, marker='o', linestyle='-', color='blue')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Cross-Validation Scores')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_poly = confusion_matrix(best_poly_fold_y_test, predicted_labels)\n",
    "\n",
    "# Visualisasi confusion matrix menggunakan heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_poly, annot=True, fmt='g', cmap='viridis', xticklabels=True, yticklabels=True)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = conf_matrix_poly[1, 1] / (conf_matrix_poly[1, 0] + conf_matrix_poly[1, 1])\n",
    "specificity = conf_matrix_poly[0, 0] / (conf_matrix_poly[0, 0] + conf_matrix_poly[0, 1])\n",
    "\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
