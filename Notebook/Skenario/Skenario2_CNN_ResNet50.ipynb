{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Skenario 2 - CNN ResNet50**\n",
    "\n",
    "Skenario 2 menggunakan model Convolutional Neural Network (CNN) dengan arsitektur ResNet50 untuk melakukan klasifikasi pada data citra otak.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages\n",
    "\n",
    "Import library yang digunakan untuk preprocessing data, membangun model, dan visualisas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('seaborn-dark')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load dan Eksplorasi Data\n",
    "cari dan cetak data `selected_image.npz` di dalam struktur direktori dan menampilkan informasi tentang jumlah slice untuk setiap label dan plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = r\"D:\\Documents\\Kuliah\\.SKRIPSI\\KLASIFIKASI ALZHEIMER\\Coding\\Notebook\\Preprocessing\\selected_image.npz\"\n",
    "loaded_data = np.load(directory_path, allow_pickle=True)\n",
    "\n",
    "combined_slices = loaded_data['combined_slices'].item()\n",
    "\n",
    "for label, plane_slices in combined_slices.items():\n",
    "    for plane, result_slices in plane_slices.items():\n",
    "        total_slices = len(result_slices)\n",
    "        \n",
    "        print(f\"Label: {label}, Plane: {plane}, Jumlah Total Slice: {total_slices}\")\n",
    "\n",
    "        # Menampilkan bentuk (shape) dari setiap slice\n",
    "        for i, (position, resized_slice) in enumerate(result_slices):\n",
    "            print(f\"  Resized Slice {i+1} - Position: {position}, Shape: {resized_slice.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pembagian Data\n",
    "\n",
    "Menyiapkan data dengan menggabungkan slice dan melakukan label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for label, plane_slices in combined_slices.items():\n",
    "    for plane, result_slices in plane_slices.items():\n",
    "        X.extend([np.expand_dims(slice_data, axis=-1) for _, slice_data in result_slices])\n",
    "        y.extend([label] * len(result_slices))\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Normalisasi dan Penyesuaian Format Citra\n",
    "Mengatur parameter untuk cross-validation dan menentukan nilai mean dan std untuk normalisasi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Perform K-Fold cross-validation\n",
    "n_splits = 5\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "mean = 0.485\n",
    "std = 0.229"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cross - Validation\n",
    "Melakukan cross-validation dengan 5 fold. Di dalam setiap fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Inisialisasi k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(kf.split(X, y), start=1):\n",
    "    # Model ResNet50 sbg base model\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "    # Setel base model gabisa dilatih\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Menyiapkan data train dan test dg label encoding\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    y_train_encoded = to_categorical(y_train, num_classes=4)\n",
    "    y_test_encoded = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "    # Normalisasi dan ubah gambar grayscale menjadi RGB\n",
    "    X_train_normalized = (X_train / 255.0 - mean) / std\n",
    "    X_test_normalized = (X_test / 255.0 - mean) / std\n",
    "\n",
    "    X_train_rgb = np.repeat(X_train_normalized, 3, axis=-1)\n",
    "    X_test_rgb = np.repeat(X_test_normalized, 3, axis=-1)\n",
    "\n",
    "    # Latih model\n",
    "    model.fit(X_train_rgb, y_train_encoded, epochs=10, validation_data=(X_test_rgb, y_test_encoded))\n",
    "\n",
    "    # Evaluasi model\n",
    "    _, accuracy_fold = model.evaluate(X_test_rgb, y_test_encoded)\n",
    "    y_pred = model.predict(X_test_rgb)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    classification_rep_fold = classification_report(np.argmax(y_test_encoded, axis=1), y_pred_labels)\n",
    "\n",
    "    # Simpan skor dan menampilkannya\n",
    "    print(f\"Fold {i} - Accuracy: {accuracy_fold}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_rep_fold)\n",
    "\n",
    "    cv_scores.append(accuracy_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy: \", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memvisualisasikan skor cross-validation dengan plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cv_scores, marker=\"o\", color=\"blue\", label=\"Cross-Validation Score\")\n",
    "plt.axhline(y=np.mean(cv_scores), color=\"red\", linestyle=\"-\", label=\"Mean Accuracy\")\n",
    "\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Cross-Validation Score vs. Fold\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Menilai model pada data uji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi model menggunakan data uji NumPy\n",
    "evaluation_result = model.evaluate(X_test_rgb, y_test_encoded, verbose=1)\n",
    "\n",
    "# Menampilkan hasil evaluasi\n",
    "print(\"Loss:\", evaluation_result[0])\n",
    "print(\"Accuracy:\", evaluation_result[1])\n",
    "\n",
    "# Prediksi menggunakan data uji\n",
    "predictions = model.predict(X_test_rgb)\n",
    "predicted_labels = tf.argmax(predictions, axis=1).numpy()\n",
    "\n",
    "print('Label Sebenarnya : ', np.argmax(y_test_encoded, axis=1))\n",
    "print('Label Prediksi : ', predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Visualisasi beberapa gambar dari data uji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"AD\", \"CN\", \"EMCI\", \"LMCI\"]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(min(9, len(X_test_rgb))):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(X_test_rgb[i].astype(\"uint8\"))\n",
    "    \n",
    "    # Dapatkan label prediksi dan label sebenarnya\n",
    "    true_label = np.argmax(y_test_encoded[i])\n",
    "    plt.title(\"Pred: \" + class_names[predicted_labels[i]] + \" | Real: \" + class_names[true_label])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menambahkan metrik specificity dan sensitivity ke model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', specificity, sensitivity])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluasi model pada data train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, specificity, sensitivity = model.evaluate(X_train_rgb, y_train_encoded)\n",
    "print('Loss train set: ', loss)\n",
    "print('Akurasi train set: ', accuracy)\n",
    "print('Specificity train set: ', specificity)\n",
    "print('Sensitivity train set: ', sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluasi model pada data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, specificity, sensitivity = model.evaluate(X_test_rgb, y_test_encoded)\n",
    "print('Loss test set: ', loss)\n",
    "print('Akurasi test set: ', accuracy)\n",
    "print('Specificity test set: ', specificity)\n",
    "print('Sensitivity test set: ', sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualisasi confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import product\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "    n_classes = cm.shape[0]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Plot confusion matrix with colorbar\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        ax=ax,\n",
    "        xticklabels=classes if classes else np.arange(n_classes),\n",
    "        yticklabels=classes if classes else np.arange(n_classes),\n",
    "        cbar_kws={\"label\": \"Count\", \"format\": \"%d\"},\n",
    "    )\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set(\n",
    "        title=\"Confusion Matrix\",\n",
    "        xlabel=\"Predicted label\",\n",
    "        ylabel=\"True label\",\n",
    "    )\n",
    "\n",
    "    # Set tick positions and labels\n",
    "    ax.xaxis.set_major_locator(plt.FixedLocator(np.arange(n_classes)))\n",
    "    ax.yaxis.set_major_locator(plt.FixedLocator(np.arange(n_classes)))\n",
    "    ax.set_xticklabels(classes if classes else np.arange(n_classes), rotation=45, fontsize=text_size)\n",
    "    ax.set_yticklabels(classes if classes else np.arange(n_classes), rotation=0, fontsize=text_size)\n",
    "\n",
    "    # Set threshold for text color\n",
    "    threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "    # Add text to each cell with percentage\n",
    "    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j + 0.5,  \n",
    "            i + 0.5,  \n",
    "            f\"{cm[i, j]} ({cm_norm[i, j] * 100:.1f}%)\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "            fontsize=text_size,\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi Label\n",
    "y_pred = model.predict(X_test_rgb)\n",
    "predicted_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Buat confusion matrix\n",
    "make_confusion_matrix(np.argmax(y_test_encoded, axis=1), predicted_labels, class_names, figsize=(10,10),\n",
    "                      text_size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisasi ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(4):  \n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_encoded[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Display ROC-AUC for each class\n",
    "for i in range(4):\n",
    "    print(f\"Class {class_names[i]} - ROC-AUC: {roc_auc[i]}\")\n",
    "\n",
    "# Visualize ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i in range(4):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-AUC Curve for Multi-Class Classification')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
