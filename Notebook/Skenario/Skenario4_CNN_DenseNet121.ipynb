{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Skenario 4 - CNN DenseNet121**\n",
    "\n",
    "Skenario 4 menggunakan model Convolutional Neural Network (CNN) dengan arsitektur DenseNet121 untuk melakukan klasifikasi pada data citra otak.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages\n",
    "\n",
    "Impor semua pustaka dan modul yang dibutuhkan untuk pemrosesan data, visualisasi, pembuatan model, dan pelatihan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load dan Eksplorasi Data\n",
    "Load dan proses data `image_selected.npz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    base_dir = r\"D:\\Users\\RESA\\Coding\\Alzheimer-Classification-with-CNN-SVM\\Notebook\\Preprocessing\\image_selected.npz\"\n",
    "    \n",
    "    # Load data from npz file\n",
    "    loaded_data = np.load(base_dir, allow_pickle=True)\n",
    "    loaded_combined_slices = loaded_data[list(loaded_data.keys())[0]]\n",
    "\n",
    "    # Prepare X dan Y lists\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    # Buat label mapping untuk tiap kelas \n",
    "    label_mapping = {'AD': 0, 'CN': 1, 'EMCI': 2, 'LMCI': 3}\n",
    "\n",
    "    # Iterate through loaded data\n",
    "    for label, plane_slices in loaded_combined_slices.item().items():\n",
    "        for plane, slices in plane_slices.items():\n",
    "            for selected_slice in slices:\n",
    "                position, resized_slice = selected_slice\n",
    "\n",
    "                # Pastikan resized_slice memiliki tiga saluran warna\n",
    "                resized_slice_rgb = cv2.cvtColor(resized_slice, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "                # Append data to X and Y\n",
    "                X.append(resized_slice_rgb)\n",
    "                Y.append(label_mapping[label])\n",
    "\n",
    "    # Convert lists ke numpy arrays\n",
    "    X = np.array(X) / 255.0  # Normalisasi\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    # Convert labels to categorical format\n",
    "    Y = to_categorical(Y, num_classes=len(set(Y)))\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panggil fungsi dan simpan ke X, Y\n",
    "X, Y = load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (7200, 224, 224, 3)\n",
      "Y shape: (7200, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi Kelas setelah One-Hot Encoding:\n",
      "{0: 1800, 1: 1800, 2: 1800, 3: 1800}\n"
     ]
    }
   ],
   "source": [
    "unique_labels, counts = np.unique(np.argmax(Y, axis=1), return_counts=True)\n",
    "class_distribution = dict(zip(tuple(unique_labels), counts))\n",
    "\n",
    "print(\"Distribusi Kelas setelah One-Hot Encoding:\")\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pembagian Data\n",
    "Data dibagi dengan rasio 80:20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cek shape dan jumlah data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi X_train: (5760, 224, 224, 3)\n",
      "Dimensi Y_train: (5760, 4)\n",
      "Dimensi X_test: (1440, 224, 224, 3)\n",
      "Dimensi Y_test: (1440, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensi X_train:\", X_train.shape)\n",
    "print(\"Dimensi Y_train:\", Y_train.shape)\n",
    "print(\"Dimensi X_test:\", X_test.shape)\n",
    "print(\"Dimensi Y_test:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah sampel dalam X_train: 5760\n",
      "Jumlah sampel dalam Y_train: 5760\n",
      "Jumlah sampel dalam X_test: 1440\n",
      "Jumlah sampel dalam Y_test: 1440\n"
     ]
    }
   ],
   "source": [
    "print(\"Jumlah sampel dalam X_train:\", len(X_train))\n",
    "print(\"Jumlah sampel dalam Y_train:\", len(Y_train))\n",
    "print(\"Jumlah sampel dalam X_test:\", len(X_test))\n",
    "print(\"Jumlah sampel dalam Y_test:\", len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Buat dan Konfigurasi Model\n",
    "Arsitektur yang digunakan yaitu DenseNet121 sebagai bagian dari transfer learning yaitu arsitektur yang sudah dilatih dengan data ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "densenet121 (Functional)     (None, 7, 7, 1024)        7037504   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 7,041,604\n",
      "Trainable params: 4,100\n",
      "Non-trainable params: 7,037,504\n",
      "_________________________________________________________________\n",
      "CPU times: total: 5.56 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_model = DenseNet121(\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create inputs dengan shape yang bnr\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "# Add pooling layer/flatten layer\n",
    "x = layers.GlobalAveragePooling2D()(x)  \n",
    "\n",
    "# Add final dense layer\n",
    "outputs = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Combine inputs and outputs untuk membuat model\n",
    "model = Model(inputs, outputs)  # Mengganti tf.keras.Model menjadi Model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Model\n",
    "Latih model dengan data `X_train dan Y_train` dan menguji kinerja model pada data validasi `X_test dan Y_test`, setelah pelatihan nanti model akan menyimpan riwayatnya ke dalam `h_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "180/180 [==============================] - 995s 5s/step - loss: 1.5042 - accuracy: 0.2937 - val_loss: 1.3575 - val_accuracy: 0.3625\n",
      "Epoch 2/25\n",
      "180/180 [==============================] - 997s 6s/step - loss: 1.2998 - accuracy: 0.3926 - val_loss: 1.3451 - val_accuracy: 0.3625\n",
      "Epoch 3/25\n",
      "180/180 [==============================] - 1049s 6s/step - loss: 1.2479 - accuracy: 0.4295 - val_loss: 1.3339 - val_accuracy: 0.3722\n",
      "Epoch 4/25\n",
      "180/180 [==============================] - 1039s 6s/step - loss: 1.1921 - accuracy: 0.4704 - val_loss: 1.2281 - val_accuracy: 0.4458\n",
      "Epoch 5/25\n",
      "180/180 [==============================] - 1025s 6s/step - loss: 1.1567 - accuracy: 0.4998 - val_loss: 1.2033 - val_accuracy: 0.4514\n",
      "Epoch 6/25\n",
      "180/180 [==============================] - 1024s 6s/step - loss: 1.1349 - accuracy: 0.5023 - val_loss: 1.1851 - val_accuracy: 0.4736\n",
      "Epoch 7/25\n",
      "180/180 [==============================] - 1019s 6s/step - loss: 1.1222 - accuracy: 0.5004 - val_loss: 1.1880 - val_accuracy: 0.4708\n",
      "Epoch 8/25\n",
      "180/180 [==============================] - 1016s 6s/step - loss: 1.1007 - accuracy: 0.5296 - val_loss: 1.2598 - val_accuracy: 0.4257\n",
      "Epoch 9/25\n",
      "180/180 [==============================] - 930s 5s/step - loss: 1.0866 - accuracy: 0.5403 - val_loss: 1.1789 - val_accuracy: 0.4806\n",
      "Epoch 10/25\n",
      "180/180 [==============================] - 842s 5s/step - loss: 1.0720 - accuracy: 0.5333 - val_loss: 1.1475 - val_accuracy: 0.5056\n",
      "Epoch 11/25\n",
      "180/180 [==============================] - 847s 5s/step - loss: 1.0632 - accuracy: 0.5420 - val_loss: 1.1496 - val_accuracy: 0.4910\n",
      "Epoch 12/25\n",
      "180/180 [==============================] - 911s 5s/step - loss: 1.0581 - accuracy: 0.5508 - val_loss: 1.1419 - val_accuracy: 0.4944\n",
      "Epoch 13/25\n",
      "180/180 [==============================] - 1036s 6s/step - loss: 1.0278 - accuracy: 0.5631 - val_loss: 1.1280 - val_accuracy: 0.5160\n",
      "Epoch 14/25\n",
      "180/180 [==============================] - 1065s 6s/step - loss: 1.0339 - accuracy: 0.5658 - val_loss: 1.1386 - val_accuracy: 0.4958\n",
      "Epoch 15/25\n",
      "180/180 [==============================] - 1049s 6s/step - loss: 1.0052 - accuracy: 0.5852 - val_loss: 1.1501 - val_accuracy: 0.5000\n",
      "Epoch 16/25\n",
      "180/180 [==============================] - 1063s 6s/step - loss: 1.0182 - accuracy: 0.5733 - val_loss: 1.1675 - val_accuracy: 0.4764\n",
      "Epoch 17/25\n",
      "180/180 [==============================] - 1017s 6s/step - loss: 1.0161 - accuracy: 0.5721 - val_loss: 1.1113 - val_accuracy: 0.5319\n",
      "Epoch 18/25\n",
      "180/180 [==============================] - 994s 6s/step - loss: 0.9961 - accuracy: 0.5824 - val_loss: 1.1389 - val_accuracy: 0.5083\n",
      "Epoch 19/25\n",
      "180/180 [==============================] - 1028s 6s/step - loss: 1.0062 - accuracy: 0.5767 - val_loss: 1.0933 - val_accuracy: 0.5403\n",
      "Epoch 20/25\n",
      "180/180 [==============================] - 1025s 6s/step - loss: 0.9955 - accuracy: 0.5905 - val_loss: 1.1083 - val_accuracy: 0.5250\n",
      "Epoch 21/25\n",
      "180/180 [==============================] - 1008s 6s/step - loss: 0.9646 - accuracy: 0.6106 - val_loss: 1.1475 - val_accuracy: 0.4931\n",
      "Epoch 22/25\n",
      "180/180 [==============================] - 976s 5s/step - loss: 0.9734 - accuracy: 0.5931 - val_loss: 1.0842 - val_accuracy: 0.5472\n",
      "Epoch 23/25\n",
      "180/180 [==============================] - 872s 5s/step - loss: 0.9675 - accuracy: 0.6010 - val_loss: 1.1877 - val_accuracy: 0.4618\n",
      "Epoch 24/25\n",
      "180/180 [==============================] - 827s 5s/step - loss: 0.9623 - accuracy: 0.5934 - val_loss: 1.1381 - val_accuracy: 0.5069\n",
      "Epoch 25/25\n",
      " 26/180 [===>..........................] - ETA: 9:55 - loss: 1.0061 - accuracy: 0.5806"
     ]
    }
   ],
   "source": [
    "# Fine-tuning\n",
    "EPOCH = 25\n",
    "h_model = model.fit(X_train, Y_train, epochs=EPOCH, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Menilai model pada data uji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi model menggunakan data uji NumPy\n",
    "evaluation_result = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# Menampilkan hasil evaluasi\n",
    "print(\"Loss:\", evaluation_result[0])\n",
    "print(\"Accuracy:\", evaluation_result[1])\n",
    "\n",
    "# Prediksi menggunakan data uji\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = tf.argmax(predictions, axis=1).numpy()\n",
    "\n",
    "print('Label Sebenarnya : ', np.argmax(Y_test, axis=1))\n",
    "print('Label Prediksi : ', predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Visualisasi beberapa gambar dari data uji\n",
    "Membuat visualisasi dari beberapa contoh hasil prediksi model pada data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"AD\", \"CN\", \"EMCI\", \"LMCI\"]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(min(9, len(X_test))):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(X_test[i].astype(\"uint8\"))\n",
    "    \n",
    "    # Dapatkan label prediksi dan label sebenarnya\n",
    "    true_label = np.argmax(Y_test[i])\n",
    "    plt.title(\"Pred: \" + class_names[predicted_labels[i]] + \" | Real: \" + class_names[true_label])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Matriks specificity dan sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', specificity, sensitivity])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluasi model pada data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, specificity, sensitivity = model.evaluate(X_train, Y_train)\n",
    "print('Loss train set: ', loss)\n",
    "print('Akurasi train set: ', accuracy)\n",
    "print('Specificity train set: ', specificity)\n",
    "print('Sensitivity train set: ', sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluasi model pada data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, specificity, sensitivity = model.evaluate(X_test, Y_test)\n",
    "print('Loss train set: ', loss)\n",
    "print('Akurasi train set: ', accuracy)\n",
    "print('Specificity train set: ', specificity)\n",
    "print('Sensitivity train set: ', sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisasi confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(h_model.history['loss'], label='loss')\n",
    "ax.plot(h_model.history['val_loss'], label='val_loss')\n",
    "ax.legend()\n",
    "plt.title('DenseNet121')\n",
    "plt.show()\n",
    "fig.savefig(r'D:\\Users\\RESA\\Coding\\Evaluasi\\DenseNet121Loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(h_model.history['accuracy'], label='acc')\n",
    "ax.plot(h_model.history['val_accuracy'], label='val acc')\n",
    "ax.legend()\n",
    "plt.title('DenseNet121')\n",
    "plt.show()\n",
    "fig.savefig(r'D:\\Users\\RESA\\Coding\\Evaluasi\\DenseNet121Accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan model\n",
    "model.save(r\"D:\\Users\\RESA\\Coding\\Evaluasi\\DenseNet121.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds =  model.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_ind = np.argmax(y_preds,axis=1)\n",
    "y_preds_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwe=np.argmax(Y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(qwe,y_preds_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(qwe,y_preds_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 ROC AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(qwe, y_preds_ind, pos_label=2)\n",
    "\n",
    "auc = auc(fpr, tpr)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1],\"--\")\n",
    "\n",
    "plt.plot(fpr, tpr, label='RF (area = {:.3f})'.format(auc), color='orange')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visualize_Result(acc,val_acc,loss, val_loss):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows = 1,\n",
    "                                   ncols = 2,\n",
    "                                   figsize = (15,6))\n",
    "\n",
    "    plot1 = ax1.plot(range(0, len(acc)),\n",
    "                     acc,\n",
    "                     label = 'accuracy')\n",
    "\n",
    "    plot2 = ax1.plot(range(0, len(val_acc)),\n",
    "                     val_acc,\n",
    "                     label = 'val_accuracy')\n",
    "\n",
    "    ax1.set(title = 'Accuracy And Val Accuracy progress',\n",
    "            xlabel = 'epoch',\n",
    "            ylabel = 'accuracy/ validation accuracy')\n",
    "\n",
    "    ax1.legend()\n",
    "\n",
    "    plot3 = ax2.plot(range(0, len(loss)),\n",
    "                     loss,\n",
    "                     label = 'loss')\n",
    "    \n",
    "    plot4 = ax2.plot(range(0, len(val_loss)),\n",
    "                     val_loss,\n",
    "                     label = 'val_loss')\n",
    "    \n",
    "    ax2.set(title = 'Loss And Val loss progress',\n",
    "            xlabel = 'epoch',\n",
    "            ylabel = 'loss/ validation loss')\n",
    "\n",
    "    ax2.legend()\n",
    "\n",
    "    fig.suptitle('Result Of Model', fontsize = 20, fontweight = 'bold')\n",
    "    fig.savefig(r'D:\\Users\\RESA\\Coding\\Evaluasi\\Accuracy_Loss_figure_DenseNet121.png')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_result = Visualize_Result(h_model.history['accuracy'],h_model.history['val_accuracy'], h_model.history['loss'], h_model.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Set early stopping criteria\n",
    "pat = 5 \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "\n",
    "# Define the model checkpoint callback\n",
    "model_checkpoint = ModelCheckpoint(r'D:\\Users\\RESA\\Coding\\Evaluasi\\h_DenseNet121.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "# Define a function to fit the model\n",
    "def fit_and_evaluate(X_train, X_test, Y_train, Y_test, EPOCHS=20, BATCH_SIZE=32, model=model):\n",
    "    results = model.fit(X_train, Y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                        callbacks=[early_stopping, model_checkpoint], verbose=1, validation_split=0.2)\n",
    "    print(\"Val Score: \", model.evaluate(X_test, Y_test))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "# Save the model history after fitting so that we can plot later\n",
    "model_history = []\n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(\"Training on Fold: \", i + 1)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,\n",
    "                                                                random_state=np.random.randint(1, 1000, 1)[0])\n",
    "    model_history.append(fit_and_evaluate(X_train, X_test, Y_train, Y_test, epochs, batch_size))\n",
    "    print(\"=======\" * 12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Evaluasi Cross - Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracies vs Epochs')\n",
    "for i in range(len(model_history)):\n",
    "  plt.plot(model_history[i].history['accuracy'], label=f\"Training Fold {i+1}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(r'D:\\Users\\RESA\\Coding\\Evaluasi\\Accuracy_vs_Epoch_DenseNet12.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Train Accuracy vs Val Accuracy')\n",
    "plt.plot(model_history[0].history['accuracy'], label='Train Accuracy Fold 1', color='black')\n",
    "plt.plot(model_history[0].history['val_accuracy'], label='Val Accuracy Fold 1', color='black', linestyle = \"dashdot\")\n",
    "plt.plot(model_history[1].history['accuracy'], label='Train Accuracy Fold 2', color='red', )\n",
    "plt.plot(model_history[1].history['val_accuracy'], label='Val Accuracy Fold 2', color='red', linestyle = \"dashdot\")\n",
    "plt.plot(model_history[2].history['accuracy'], label='Train Accuracy Fold 3', color='green', )\n",
    "plt.plot(model_history[2].history['val_accuracy'], label='Val Accuracy Fold 3', color='green', linestyle = \"dashdot\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(r'D:\\Users\\RESA\\Coding\\Evaluasi\\TrainAccuracy_vs_ValAccuracy_DenseNet121.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
