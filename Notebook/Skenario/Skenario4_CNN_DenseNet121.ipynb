{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Skenario 4 - CNN DenseNet121**\n",
    "\n",
    "Skenario 4 menggunakan model Convolutional Neural Network (CNN) dengan arsitektur DenseNet121 untuk melakukan klasifikasi pada data citra otak.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages\n",
    "\n",
    "Import library yang digunakan untuk preprocessing data, membangun model, dan visualisas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load dan Eksplorasi Data\n",
    "cari dan cetak data `selected_image.npz` di dalam struktur direktori dan menampilkan informasi tentang jumlah slice untuk setiap label dan plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data yang dimuat:\n",
      "Label: coronal, Jumlah Total Slice: 600\n",
      "Label: axial, Jumlah Total Slice: 600\n",
      "Label: sagittal, Jumlah Total Slice: 600\n"
     ]
    }
   ],
   "source": [
    "base_dir = r\"D:\\Users\\RESA\\Coding\\Alzheimer-Classification-with-CNN-SVM\\Notebook\\Preprocessing\\selected_images.npz\"\n",
    "\n",
    "# Memuat data dari file npz yang berbeda\n",
    "loaded_data = np.load(base_dir, allow_pickle=True)\n",
    "\n",
    "# Mendapatkan data dari objek array di dalam file .npz\n",
    "loaded_combined_slices = loaded_data[list(loaded_data.keys())[0]]\n",
    "\n",
    "# Contoh cara mengakses data yang dimuat\n",
    "print(\"Data yang dimuat:\")\n",
    "for label, plane_slices in loaded_combined_slices.item().items():\n",
    "    total_slices = len(plane_slices)\n",
    "    print(f\"Label: {label}, Jumlah Total Slice: {total_slices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pembagian Data\n",
    "\n",
    "Menyiapkan data dengan menggabungkan slice dan melakukan label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(loaded_combined_slices.item().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=3.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      5\u001b[0m stratified_kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mn_splits, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(stratified_kfold\u001b[38;5;241m.\u001b[39msplit(labels, labels)):\n\u001b[0;32m      8\u001b[0m     train_data \u001b[38;5;241m=\u001b[39m {label: loaded_combined_slices\u001b[38;5;241m.\u001b[39mitem()[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels[train_index]}\n\u001b[0;32m      9\u001b[0m     test_data \u001b[38;5;241m=\u001b[39m {label: loaded_combined_slices\u001b[38;5;241m.\u001b[39mitem()[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels[test_index]}\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_split.py:370\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    368\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    371\u001b[0m         (\n\u001b[0;32m    372\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    374\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    375\u001b[0m     )\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=3."
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits = 5\n",
    "stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(stratified_kfold.split(labels, labels)):\n",
    "    train_data = {label: loaded_combined_slices.item()[label] for label in labels[train_index]}\n",
    "    test_data = {label: loaded_combined_slices.item()[label] for label in labels[test_index]}\n",
    "\n",
    "    train_dir = os.path.join(base_dir, f'train_fold_{fold+1}')\n",
    "    test_dir = os.path.join(base_dir, f'test_fold_{fold+1}')\n",
    "\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Save slices to training directory\n",
    "    for label, plane_slices in train_data.items():\n",
    "        label_dir = os.path.join(train_dir, label)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "        for idx, slice_data in enumerate(plane_slices):\n",
    "            slice_path = os.path.join(label_dir, f'slice_{idx}.npy')\n",
    "            np.save(slice_path, slice_data)\n",
    "\n",
    "    # Save slices to testing directory\n",
    "    for label, plane_slices in test_data.items():\n",
    "        label_dir = os.path.join(test_dir, label)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "        for idx, slice_data in enumerate(plane_slices):\n",
    "            slice_path = os.path.join(label_dir, f'slice_{idx}.npy')\n",
    "            np.save(slice_path, slice_data)\n",
    "\n",
    "    print(f'Fold {fold+1}: Total slices train - {sum(len(os.listdir(os.path.join(train_dir, label))) for label in labels)}, Total slices test - {sum(len(os.listdir(os.path.join(test_dir, label))) for label in labels)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
